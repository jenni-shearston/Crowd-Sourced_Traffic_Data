# Tutorial: Create Google Traffic Timeseries: Spatial Points w Buffers
# Project: Acquisition and Analysis of Crowd-Sourced Traffic Data at Varying Spatial Scales
# Script Authors: Jenni A. Shearston and Sebastian T. Rowland
# Updated: 03/07/2022

####***********************
#### Table of Contents #### 
####***********************

# N: Notes
# 0: Preparation 
# 1: Convert Points to sf Object
# 2: Prepare Polygon and Raster Inputs
# 3: Prepare Vectors of captured_datetimes of Interest
# 4: Create Google Traffic timeseries: Points w Buffer

####**************
#### N: Notes ####
####**************

# Na Description
# In this script we present a tutorial for creating a time series from processed
# Google Traffic images, for spatial points with buffers. As an example, 
# we include one week of processed data for a subset of the NYC area
# (every 3-hrs, n=56 images), and create a timeseries aggregated to very small buffers
# around three points in the South Bronx. Users can edit the parameters described
# below to complete their own analysis with differing traffic map areas, time periods,
# and points/buffers. It is not possible to use a buffer size of 0 in this script, as that 
# equates to using no pixels. Very very small radius.deg values of ~ 0.00001 (depending on zoom level) 
# can be used to represent a single pixel, but this is not recommended as it is very difficult
# to be precise enough for the lat/long of the point to both be on a road and also not only
# background. Using ~ 25 pixels (radius.deg ~ 0.000075) as a point will produce more reliable results. 
# We strongly recommend you clone this repository to ensure you 
# have the same file structure and subfolders as used in the script and functions
# used below. For definitions of variables created in timeseries output, see Rglossary.

# Nb For your own analysis
# Here we list everything you will need to change to run a version of
# this script with your own data.
# You will need to add your own files to the following directories:
#     data/gt_refs: add a geotiff from the Google Traffic map area you have data 
#       for that has been georeferenced and projected in WGS84 (gt_geo_projected)
#       and specify the name of that file (line 149)
#     data/gt_image_cat: add a processed Google Traffic image from your traffic
#       map area (captured_datetime is arbitrary) and specify file name (line 161)
# You will need to assign the following directories: 
#     dir_output_points: the file path where the points/buffers shapefile should be saved (line 105)
#     gt_dir: the file path where processed Google Traffic images are stored (line 220)
#     dir_output: the file path where output files should be saved (line 246)
#     For directories, note that the root of the directory is specified
#     to be the R project package (confirm with 'here()'), so include the file 
#     path from the R project location rather than the full file path
# You will need to specify the following variables/names:
#     points_lats: vector of latitudes of all points to be analyzed (line 102)
#     points_lons: vector of longitudes of all points to be analyzed (line 103)
#     points_ids: vector of unique ids for each point, coercible to numeric (line 104)
#     name_output_points: name to use when saving the output shapefile containing the points/buffers (line 106)
#     radius.deg: the radius of the desired buffer, in decimal degrees (line 116)
#     base_date: the base or start datetime for your analysis (line 213)
#     end_date: the end datetime for your analysis (line 214)
#     name_output: the name you would like to give specific files to save them (line 247)

####********************
#### 0: Preparation #### 
####********************

# 0a Specify needed packages
packages <- c('tidyverse', 'raster', 'rgdal', 'terra', 'sf', 'here', 'doParallel', 'sp',
              'tictoc', 'png', 'fst', 'lubridate', 'stringr', 'parallel', 'foreach')

# 0b Load or install and load all packages
lapply(packages, FUN = function(x){
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)}
})
rm(packages)

# 0c Source our functions
# 0c.i Get the names of all of the scripts that are just functions
myFunctions <- list.files(path = here::here('Rfunctions'))

# 0c.ii Define function to run sources 
source_myFunction <- function(FunctionName){
  source(here::here('Rfunctions', FunctionName))
}

# 0c.iii Source all the function scripts
#        Note: We don't actually need the assignment, it just 
#              removes annoying output generated by the sourcing code. 
#              Since we are just sourcing these, we can use map. 
a <- purrr::map(myFunctions, source_myFunction)
rm(a, myFunctions)

####************************************
#### 1: Convert Points to sf Object #### 
####************************************

# 1a Specify lat, lon, and id values for each point and the directory for and name of 
#    the output file
#    Note: id values must be coercible to numeric inputs
points_lats <- c(40.806127, 40.800692, 40.803949)
points_lons <- c(-73.923284, -73.913945, -73.919535)
points_ids <- c(1, 2, 3)
dir_output_points <- 'bronx_example_points'
name_output_points <- 'bronx_example_points.shp'

# 1b Convert points to a single sf object w buffer of variable size
#    Note: You must specify at least a small buffer, as a radius.deg value of 0 corresponds
#          to including 0 pixels. At zoom=15 in the NYC area, 1 pixel ~ 5m. To represent
#          a single point, we recommend a radius.deg value that corresponds to ~ 25 pixels
#          Here, we use 0.000075 decimal degrees (~ 125 m)
point_to_sf_wbuffer(point_lats = points_lats,
                    point_lons = points_lons,
                    point_ids = points_ids,
                    radius.deg = 0.000075,
                    dir_output = dir_output_points,
                    name_output = name_output_points) 

# 1c Read in sf object as shapefile of interest
polygons_of_interest <- st_read(here::here('outputs', 'Rtutorials',
                                           dir_output_points, name_output_points))

# 1d Specify poly_id_var
poly_id_var <- 'point_id'

####*******************************************
#### 2: Prepare Polygon and Raster Inputs #### 
####*******************************************

# The code in sections 2 and 3 needs to be run before the get_gt_agg_timeseries  
# function that loops through every Google Traffic image (gt_image_cat) 
# to put all key variables and datasets in the Global Environment 

# 2a Rename the poly_id and remove non-essential variables 
polygons_of_interest <- polygons_of_interest %>% 
  dplyr::rename(poly_id = !!poly_id_var) %>% 
  dplyr::select(poly_id)

# 2b Make poly_id numeric
polygons_of_interest <- polygons_of_interest %>% 
  dplyr::mutate(poly_id = as.numeric(poly_id))

# 2c Read in gt_geo_projected
#    Note: Replace 'gt_geo_projected' with a Geotiff from your Google 
#          Traffic map area that has been georeferenced and projected 
#          using WGS84
gt_geo_projected <- raster::raster(here::here('data', 'gt_refs',
                                              'gt_geo_projected.tif'))

# 2d Extract the extent (min and max lat and long) of gt_geo_projected 
#    Note: We use gt_geo_projected's extent because we have carefully 
#          georeferenced it
gt_extent <- raster::extent(gt_geo_projected)

# 2e Read a gt_image_cat.png as a matrix
#    Note: The actual datetime of this image is arbitrary. Replace 
#          'CCC_01_01_18__02_00.png' with a processed and categorized
#          image from your own Google Traffic map area
gt_matrix_cat <- png::readPNG(here::here('data', 'gt_image_cat', 
                                         'CCC_01_01_18__02_00.png'))

# 2f Convert gt_matrix_unprojected to raster
gt_raster_unprojected <- raster::raster(gt_matrix_cat) 

# 2g Change the extent of gt_raster_unprojected to reflect the extent of the gt_extent 
#    Note: Now we are converting it to lat long 
#          Here we georeference gt_raster_unprojected based on the location of 
#          gt_geo_projected which was georeferenced carefully
raster::extent(gt_raster_unprojected) <- c(gt_extent[1], gt_extent[2], gt_extent[3], gt_extent[4])

# 2h Convert polygons_of_interest CRS to WGS84 
#    Note: This is important because gt_raster_projected has a CRS of WGS84 which 
#          uses lat/long and not decimal degrees or feet 
#          Because gt_raster_unprojected has been assigned the extent of 
#          gt_raster_projected, which is in lat/long, the polygons_of_interest
#          file must have a CRS in lat/long in order for the rasterize
#          command to clip the shapefile to the gt_raster_unprojected's extent
polygons_of_interest_wgs84 <- sf::st_set_crs(polygons_of_interest, value = "WGS84")

# 2i Convert polygons_of_interest to a raster with the dimensions and 
#    resolution of gt_raster_unprojected (~ 30s to 2min)
#    Note: The resulting raster will only have cells within the area defined by the 
#          overlap of gt_raster_unprojected and the polygons of interest 
#          The raster will have one column - the id of the polygon the cell belongs to
poly_gt_crosswalk <- raster::rasterize(polygons_of_interest_wgs84, 
                                       gt_raster_unprojected, field = "poly_id")

# 2j Convert to matrix
poly_matrix <- raster::as.matrix(poly_gt_crosswalk)

# 2k Remove no longer needed files and run garbage collection to 
#    return memory 
#    Note: This is critical to conserve memory
rm(poly_gt_crosswalk, polygons_of_interest_wgs84, 
   gt_raster_unprojected, gt_extent, gt_geo_projected,
   gt_matrix_cat)
gc()

####**********************************************************
#### 3: Prepare vectors of captured_datetimes of interest #### 
####**********************************************************

# 3a Create vector of captured_datetimes of interest
#    Note: Here we use March 17, 2020 through March 24, 2020
#          Processed images for a subset of the NYC area are included in
#          the data folder for this time period, at 3-hour intervals (n = 56).
#          There is no need to specify only the specific 3-hour intervals in your
#          captured datetime vector; the function will fill an NA for any datetimes
#          between the base_date and end_date that gt_image_cats are not present for
#          Change the base_date and end_date to reflect your datetimes of interest.
captured_datetime_vector <- make_captured_datetime_vector(
  base_date = '2020/03/17 00:30',
  end_date = '2020/03/24 21:30')

# 3b Set directory where processed Google Traffic images are stored
#    Note: Change this directory to lead to where your processed Google Traffic
#          images are stored. Note that the root directory should be this R package
#          Check with 'here()' command to confirm
gt_dir <- here::here('data', 'gt_image_cat', 'bronx_example')

# 3c Reformat vector of captured_datetimes of interest
captured_datetime_vector_formatted <- reformat_captured_datetime_vector(
  captured_datetime_vector = captured_datetime_vector, 
  gt_dir = gt_dir)


####***************************************************
#### 4: Create Google Traffic timeseries: polygons #### 
####***************************************************

# 4a Run function to aggregate Google Traffic images to polygons
#    Note: Set the file path where you would like the .fst file containing 
#          the time series to be saved by assigning dir_output. Note that the 
#          root directory should be this R package - check with 'here()' command to confirm
#          Change the name you would like the .fst file to have with name_output
#          It is highly recommended that you first run the function for one 
#          week of time, to get a sense of how long it will take to run
#          your full datetime vector. A year's worth of analysis for a large
#          city at hourly resolution may take ~ 10-15 hours.
#          method can be set to 'parallel' to use parallelization (n-1 cores) 
#          or 'forloop' to use a single core
tictoc::tic('completes 1 week of 3 bronx sites')
gt_timeseries <- 
  get_gt_agg_timeseries(captured_datetime_vector_filename = captured_datetime_vector_formatted, 
                        dir_output = 'outputs/Rtutorials', 
                        name_output = 'bronx_pointswbuffer_example_timeseries',
                        gt_dir = gt_dir,
                        method = 'parallel')
tictoc::toc()






