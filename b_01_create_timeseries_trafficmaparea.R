# Tutorial: Create Google Traffic Timeseries: Entire Traffic Map Area
# Project: Acquisition and Analysis of Crowd-Sourced Traffic Data at Varying Spatial Scales
# Script Authors: Jenni A. Shearston and Sebastian T. Rowland
# Updated: 03/07/2022

####***********************
#### Table of Contents #### 
####***********************

# N: Notes
# 0: Preparation 
# 1: Prepare Vectors of captured_datetimes of Interest
# 2: Create Google Traffic timeseries: Entire Traffic Map Area

####**************
#### N: Notes ####
####**************

# Na Description
# In this script we present a tutorial for creating a time series from processed
# Google Traffic images, for the entire traffic map area. As an example, we include one week of 
# processed data for a subset of the NYC area (every 3-hrs, n=56 images), and create a time
# series including all datetimes. Users can edit the parameters described
# below to complete their own analysis with differing traffic map areas and time periods.
# We strongly recommend you clone this repository to ensure you 
# have the same file structure and subfolders as used in the script and functions
# used below. For definitions of variables created in timeseries output, see Rglossary.

# Nb For your own analysis
# Here we list everything you will need to change to run your own version of
# this script.
# You will need to assign the following directories: 
#     gt_dir: the file path where processed Google Traffic images are stored (line 96)
#     dir_output: the file path where you would like the .fst file containing 
#       the time series to be saved (line 121)
#     For directories, note that the root of the directory is specified
#     to be the R project package (confirm with 'here()'), so include the file 
#     path from the R project location rather than the full file path
# You will need to specify the following variables/names:
#     base_date: the base or start datetime for your analysis (line 89)
#     end_date: the end datetime for your analysis (line 90)
#     name_output: the name you would like to give the .fst file with the timeseries (line 122)

####********************
#### 0: Preparation #### 
####********************

# 0a Specify needed packages
packages <- c('tidyverse', 'raster', 'rgdal', 'terra', 'sf', 'here', 'doParallel',
              'tictoc', 'png', 'fst', 'lubridate', 'stringr', 'parallel', 'foreach')

# 0b Load or install and load all packages
lapply(packages, FUN = function(x){
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)}
})
rm(packages)

# 0c Source our functions
# 0c.i Get the names of all of the scripts that are just functions
myFunctions <- list.files(path = here::here('Rfunctions'))

# 0c.ii Define function to run sources 
source_myFunction <- function(FunctionName){
  source(here::here('Rfunctions', FunctionName))
}

# 0c.iii Source all the function scripts
#        Note: We don't actually need the assignment, it just 
#              removes annoying output generated by the sourcing code. 
#              Since we are just sourcing these, we can use map. 
a <- purrr::map(myFunctions, source_myFunction)
rm(a, myFunctions)

####**********************************************************
#### 1: Prepare Vectors of captured_datetimes of Interest #### 
####**********************************************************

# 1a Create vector of captured_datetimes of interest
#    Note: Here we use January 10, 2020 through January 16, 2020
#          Processed images for a subset of the NYC area are included in
#          the data folder for this time period, at 3-hour intervals (n = 56).
#          There is no need to specify only the specific 3-hour intervals in your
#          captured datetime vector; the function will fill an NA for any datetimes
#          between the base_date and end_date that gt_image_cats are not present for
#          Change the base_date and end_date to reflect your datetimes of interest.
captured_datetime_vector <- make_captured_datetime_vector(
  base_date = '2020/01/10 00:30',
  end_date = '2020/01/16 21:30')

# 1b Set directory where processed Google Traffic images are stored
#    Note: Change this directory to lead to where your processed Google Traffic
#          images are stored. Note that the root directory should be this R package
#          Check with 'here()' command to confirm
gt_dir <- here::here('data', 'gt_image_cat', 'bronx_example')

# 1c Reformat vector of captured_datetimes of interest
captured_datetime_vector_formatted <- reformat_captured_datetime_vector(
  captured_datetime_vector = captured_datetime_vector, 
  gt_dir = gt_dir)

####******************************************************************
#### 2: Create Google Traffic timeseries: Entire Traffic Map Area #### 
####******************************************************************

# 2a Run function to count pixels in Google Traffic images
#    Note: Set the file path where you would like the .fst file containing 
#          the time series to be saved by assigning dir_output. Note that the 
#          root directory should be this R package - check with 'here()' command to confirm
#          Change the name you would like the .fst file to have with name_output
#          It is highly recommended that you first run the function for one 
#          week of time, to get a sense of how long it will take to run
#          your full datetime vector. A year's worth of analysis for a large
#          city at hourly resolution may take ~ 1-2 hours.
#          method can be set to 'parallel' to use parallelization (n-1 cores) 
#          or 'forloop' to use a single core
tictoc::tic('completes 1 week of NYC subset')
gt_timeseries <- 
  get_gt_timeseries(captured_datetime_vector_filename = captured_datetime_vector_formatted, 
                    dir_output = 'outputs/Rtutorials', 
                    name_output = 'nyc_subarea_example_timeseries',
                    gt_dir = gt_dir,
                    method = 'parallel')
tictoc::toc()






